{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Report.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMx1PwyZwfL76VmY3Ys9Feq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamkritz/nhlgames/blob/adam_branch/Final%20Report%20(.ipynb)/Final_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "yoooo did you know you can save directly from colab to github? kinda sick. the path is: Final Report (.ipynb)/Final_Report.ipynb"
      ],
      "metadata": {
        "id": "BYj_5kLveUvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "yHlDlg9tWeXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Motivation and Background"
      ],
      "metadata": {
        "id": "Yt7V84DEaHHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hockey predictions have become a hot topic in recent years. Hockey fans praise hockey's unpredictability, citing how exciting it is to know that any team has a chance. This is usually contrasted with sports like basketball, where it is rare to for underdogs to win. [Here is a video](https://www.youtube.com/watch?v=c4fFOu8nyeM) of former NBA star and current NBA commentator Charles Barkley talking about why he enjoys hockey playoffs, saying that \"you have no idea who is going to win.\" Vox put out [a video](https://www.youtube.com/watch?v=HNlgISa9Giw) on this phenomenon as well, claiming that the reason that hockey underdogs do better than basketball is due to a higher luck element in hockey. \n",
        "\n",
        "But is hockey really so difficult to predict? Compared to other sports, hockey analytics are minimal. The few hockey betting sites that exist use extremely simple algorithms to predict which team will win, and often get it wrong. There is very little other published work about hockey analysis, mostly results from other projects with varying success. Either teams and other groups are not using complex analytics, or they do not want to publish their work publicly. \n",
        "\n",
        "Our project will attempt to answer whether hockey is a difficult sport to predict. We will use multiple modeling techniques and select the best model to predict the result of hockey games.\n"
      ],
      "metadata": {
        "id": "uxw9vFfRlugF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Source and Description"
      ],
      "metadata": {
        "id": "wLVN9jN0Z3yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data comes from the [NHL Game Dataset](https://www.kaggle.com/datasets/martinellis/nhl-game-data) on Kaggle. The dataset was uploaded by Martin Ellis and most recently updated a year ago. The dataset contains data pulled from NHL.com. \n",
        "\n",
        "The dataset is incredibly robust, and contains multiple .csv files full of data on players, coaches, teams, and games. For our project, we will only be using three of these files, games.csv, game_teams_stats.csv, and team_info.csv. Games.csv contains information about he games that happened, game_teams_stats.csv contains information about the teams that played in those games, and team_info.csv is the connecting set for these two files. \n",
        "\n"
      ],
      "metadata": {
        "id": "9GSXurLZjzsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NHL and Hockey Terms"
      ],
      "metadata": {
        "id": "r7oMg0ZKZzrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The NHL contains now 32 teams in the US and Canada, though our project will only include data on 31 of these teams, as the Seattle Kraken only joined the league in 2022. It is also important to note that some of these teams have moved, disbanded, or been created throughout the years. For example, the Atlanta Thrashers moved to Winnipeg and became the Jets in 2011. Teams that moved to a new location will be treated as different teams. \n",
        "\n",
        "NHL teams play 82 games in the regular season, barring any lockouts, COVID related delays, or other issues. 16 teams qualify for the playoffs and play in a four-round, single elimination bracket. Our analysis will include both playoff and regular season games, and will not differentiate between the two. \n",
        "\n",
        "Our analysis will contain many variables to help predict the outcome of games. Some hockey terms that are helpful to know include the following:\n",
        "\n",
        "- Shots - Shots in hockey are defined as shots on goal that the goalie saves.\n",
        "\n",
        "- Hits - A hit is when a player removes an opposing player from the puck, usually by running into them.\n",
        "\n",
        "- PIM - Stands for penalties in minutes. Players who receive a penalty usually go to the penalty box for a designated period of time.\n",
        "\n",
        "- Powerplay - When one team gets a penalty the other team will get to play with more players on the ice than them, as one or more of their players are in the penalty box. This is called a powerplay. \n",
        "\n",
        "- Faceoff - When the referee drops the puck to start a play, and two players compete to win possession of it. \n",
        "\n",
        "- Giveaway - When a player's own actions result in the loss of the puck\n",
        "\n",
        "- Takeaway - When a player's actions on the team without the puck result in them taking the puck from a player on the team with it. \n",
        "\n",
        "- Points - A hockey team earns 2 points for a win, 0 points for a loss, and 1 point for a loss in overtime or a shootout.\n",
        "\n",
        "- Point Percentage - Points/(Games Played * 2)"
      ],
      "metadata": {
        "id": "fRuow2MgjzMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Goal"
      ],
      "metadata": {
        "id": "A1pK3tboXJ3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to create a model that can successfully predict the winner of NHL games better statistically better than 50% accuracy. (Once we get the number of games we are predicting on we can do a 99% confidence interval for better than 50%). "
      ],
      "metadata": {
        "id": "qQtN9phoj0MS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Configuration"
      ],
      "metadata": {
        "id": "tX1i8YVHWimM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copied over the usual setup, though we may want to change some later (like the matplotlib stuff)"
      ],
      "metadata": {
        "id": "ygMoK6kVZn_k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3yB94KtgMHu"
      },
      "source": [
        "## Google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWmYBTOwgNs-",
        "outputId": "908d7ea3-ed2c-4dac-e8c4-01b0b6963287",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Get the absolute path of the current folder\n",
        "abspath_curr = '/content/drive/My Drive/Colab Notebooks/teaching/gwu/machine_learning_I/homework/homework_5/'\n",
        "\n",
        "# Get the absolute path of the deep utilities folder\n",
        "abspath_util_deep = '/content/drive/My Drive/Colab Notebooks/teaching/gwu/machine_learning_I/code/utilities/p3_deep_learning/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYZhU1Wqgmqx"
      },
      "source": [
        "## Warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUl4k83e4ANR"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WMODpPfgn2U"
      },
      "source": [
        "## Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBRVH9SB4ANb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "# Set matplotlib sizes\n",
        "plt.rc('font', size=20)\n",
        "plt.rc('axes', titlesize=20)\n",
        "plt.rc('axes', labelsize=20)\n",
        "plt.rc('xtick', labelsize=20)\n",
        "plt.rc('ytick', labelsize=20)\n",
        "plt.rc('legend', fontsize=20)\n",
        "plt.rc('figure', titlesize=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-wNDk5nZhhO"
      },
      "source": [
        "## TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjG43tEnZkfE"
      },
      "outputs": [],
      "source": [
        "# The magic below allows us to use tensorflow version 2.x\n",
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40FN3UNfO2Z7"
      },
      "source": [
        "## Random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSADk0hJP71d"
      },
      "outputs": [],
      "source": [
        "# The random seed\n",
        "random_seed = 42\n",
        "\n",
        "# Set random seed in tensorflow\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "# Set random seed in numpy\n",
        "import numpy as np\n",
        "np.random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "FdLHdRNRWveb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing"
      ],
      "metadata": {
        "id": "bsAAp_-U4gLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We took the data initially hosted on Kaggle and moved it to Github to make it easier to import."
      ],
      "metadata": {
        "id": "TANgdsE8YfUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "game = pd.read_csv('https://raw.githubusercontent.com/adamkritz/nhlgames/main/Data/game.csv')\n",
        "team_stats = pd.read_csv('https://raw.githubusercontent.com/adamkritz/nhlgames/main/Data/game_teams_stats.csv')\n",
        "team_info = pd.read_csv('https://raw.githubusercontent.com/adamkritz/nhlgames/main/Data/team_info.csv')"
      ],
      "metadata": {
        "id": "VZlqqcD9e2YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "This code was taken from: https://github.com/yuxiaohuang/teaching/blob/master/gwu/machine_learning_I/spring_2022/code/p2_shallow_learning/p2_c2_supervised_learning/p2_c2_s5_tree_based_models/case_study/case_study.ipynb \n",
        "\n",
        "These three models are a culmination of all the models we learned for classification. It has logistic regression, shallow neural networks, and random forest classifier (and als the histgradientboosting one). This was used to classify titanic survival as Yes or No, so it will probably be good for us."
      ],
      "metadata": {
        "id": "1RYCaKJSWxGj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYCH8GB-e31z"
      },
      "source": [
        "## Creating the dictionary of the models\n",
        "- In the dictionary:\n",
        "    - the key is the acronym of the model\n",
        "    - the value is the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5h3IQo9e31z"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "models = {'lr': LogisticRegression(class_weight='balanced', random_state=random_seed),\n",
        "          'mlpc': MLPClassifier(early_stopping=True, random_state=random_seed),\n",
        "          'rfc': RandomForestClassifier(class_weight='balanced', random_state=random_seed),\n",
        "          'hgbc': HistGradientBoostingClassifier(random_state=random_seed)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju9FdEVce310"
      },
      "source": [
        "## Creating the dictionary of the pipelines\n",
        "In the dictionary:\n",
        "- the key is the acronym of the model\n",
        "- the value is the pipeline, which, for now, only includes the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc-L-914e310"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipes = {}\n",
        "\n",
        "for acronym, model in models.items():\n",
        "    pipes[acronym] = Pipeline([('model', model)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgkFbGGKe311"
      },
      "source": [
        "## Getting the predefined split cross-validator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FAACb8ke311",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get the:\n",
        "# feature matrix and target velctor in the combined training and validation data\n",
        "# target vector in the combined training and validation data\n",
        "# PredefinedSplit\n",
        "# See the implementation in pmlm_utilities.ipynb\n",
        "X_train_val, y_train_val, ps = get_train_val_ps(X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3rZoMqZe312"
      },
      "source": [
        "## GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E08xqUQve313"
      },
      "source": [
        "### Creating the dictionary of the parameter grids\n",
        "- In the dictionary:\n",
        "    - the key is the acronym of the model\n",
        "    - the value is the parameter grid of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3OWujL3e313"
      },
      "outputs": [],
      "source": [
        "param_grids = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EyKhepjmV6P"
      },
      "source": [
        "#### The parameter grid for LogisticRegression\n",
        "- The hyperparameters we want to fine-tune are:\n",
        "    - tol\n",
        "    - C\n",
        "- See details of the meaning of the hyperparametes in [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2Mv1rffnJpN"
      },
      "outputs": [],
      "source": [
        "# The parameter grid of tol\n",
        "tol_grid = [10 ** -5, 10 ** -4, 10 ** -3]\n",
        "\n",
        "# The parameter grid of C\n",
        "C_grid = [0.1, 1, 10]\n",
        "\n",
        "# Update param_grids\n",
        "param_grids['lr'] = [{'model__tol': tol_grid,\n",
        "                      'model__C': C_grid}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bco06XPK4APO"
      },
      "source": [
        "#### The parameter grid for MLPClassifier\n",
        "- The hyperparameters we want to fine-tune are:\n",
        "    - alpha\n",
        "    - learning_rate_init\n",
        "\n",
        "- See details of the meaning of the hyperparametes in [sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEuags7e4APO"
      },
      "outputs": [],
      "source": [
        "# The grids for alpha\n",
        "alpha_grids = [10 ** i for i in range(-5, -2)]\n",
        "\n",
        "# The grids for learning_rate_init\n",
        "learning_rate_init_grids = [10 ** i for i in range(-4, -1)]\n",
        "\n",
        "# Update param_grids\n",
        "param_grids['mlpc'] = [{'model__alpha': alpha_grids,\n",
        "                        'model__learning_rate_init': learning_rate_init_grids}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Synl8u9cC8"
      },
      "source": [
        "#### The parameter grid for random forest\n",
        "- The hyperparameters we want to fine-tune are:\n",
        "    - min_samples_split\n",
        "    - min_samples_leaf\n",
        "\n",
        "- See details of the meaning of the hyperparametes in [sklearn.ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pIhWeST9cC8"
      },
      "outputs": [],
      "source": [
        "# The grids for min_samples_split\n",
        "min_samples_split_grids = [2, 20, 100]\n",
        "\n",
        "# The grids for min_samples_leaf\n",
        "min_samples_leaf_grids = [1, 20, 100]\n",
        "\n",
        "# Update param_grids\n",
        "param_grids['rfc'] = [{'model__min_samples_split': min_samples_split_grids,\n",
        "                       'model__min_samples_leaf': min_samples_leaf_grids}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmuPjEKN9cC-"
      },
      "source": [
        "#### The parameter grid for histogram-based gradient boosting\n",
        "- The hyperparameters we want to fine-tune are:\n",
        "- learning_rate\n",
        "- min_samples_leaf\n",
        "\n",
        "- See details of the meaning of the hyperparametes in [sklearn.ensemble.HistGradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAj6ezza9cC-"
      },
      "outputs": [],
      "source": [
        "# The grids for learning_rate\n",
        "learning_rate_grids = [10 ** i for i in range(-3, 2)]\n",
        "\n",
        "# The grids for min_samples_leaf\n",
        "min_samples_leaf_grids = [1, 20, 100]\n",
        "\n",
        "# Update param_grids\n",
        "param_grids['hgbc'] = [{'model__learning_rate': learning_rate_grids,\n",
        "                        'model__min_samples_leaf': min_samples_leaf_grids}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRabeGs4WaHX"
      },
      "source": [
        "### Creating the directory for the cv results produced by GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO7Yd15JWaHY"
      },
      "outputs": [],
      "source": [
        "# Make directory\n",
        "directory = os.path.dirname(abspath_curr + '/result/titanic/cv_results/GridSearchCV/')\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVIuo08Ze31-"
      },
      "source": [
        "### Tuning the hyperparameters\n",
        "The code below shows how to fine-tune the hyperparameters of SGDRegressor and LinearRegression_MBGD using sklearn GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "DwA4WZlFe31-",
        "outputId": "e8a5f8fc-0f40-499d-85f3-be192bb5534d",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_score</th>\n",
              "      <th>best_param</th>\n",
              "      <th>best_estimator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.827220</td>\n",
              "      <td>{'model__learning_rate': 0.1, 'model__min_samp...</td>\n",
              "      <td>(HistGradientBoostingClassifier(l2_regularizat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.802505</td>\n",
              "      <td>{'model__min_samples_leaf': 1, 'model__min_sam...</td>\n",
              "      <td>((DecisionTreeClassifier(ccp_alpha=0.0, class_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.773968</td>\n",
              "      <td>{'model__alpha': 1e-05, 'model__learning_rate_...</td>\n",
              "      <td>(MLPClassifier(activation='relu', alpha=1e-05,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.765205</td>\n",
              "      <td>{'model__C': 1, 'model__tol': 1e-05}</td>\n",
              "      <td>(LogisticRegression(C=1, class_weight='balance...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_score  ...                                     best_estimator\n",
              "0    0.827220  ...  (HistGradientBoostingClassifier(l2_regularizat...\n",
              "1    0.802505  ...  ((DecisionTreeClassifier(ccp_alpha=0.0, class_...\n",
              "2    0.773968  ...  (MLPClassifier(activation='relu', alpha=1e-05,...\n",
              "3    0.765205  ...  (LogisticRegression(C=1, class_weight='balance...\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "execution_count": 62,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# The list of [best_score_, best_params_, best_estimator_] obtained by GridSearchCV\n",
        "best_score_params_estimator_gs = []\n",
        "\n",
        "# For each model\n",
        "for acronym in pipes.keys():\n",
        "    # GridSearchCV\n",
        "    gs = GridSearchCV(estimator=pipes[acronym],\n",
        "                      param_grid=param_grids[acronym],\n",
        "                      scoring='f1_macro',\n",
        "                      n_jobs=2,\n",
        "                      cv=ps,\n",
        "                      return_train_score=True)\n",
        "        \n",
        "    # Fit the pipeline\n",
        "    gs = gs.fit(X_train_val, y_train_val)\n",
        "    \n",
        "    # Update best_score_params_estimator_gs\n",
        "    best_score_params_estimator_gs.append([gs.best_score_, gs.best_params_, gs.best_estimator_])\n",
        "    \n",
        "    # Sort cv_results in ascending order of 'rank_test_score' and 'std_test_score'\n",
        "    cv_results = pd.DataFrame.from_dict(gs.cv_results_).sort_values(by=['rank_test_score', 'std_test_score'])\n",
        "    \n",
        "    # Get the important columns in cv_results\n",
        "    important_columns = ['rank_test_score',\n",
        "                         'mean_test_score', \n",
        "                         'std_test_score', \n",
        "                         'mean_train_score', \n",
        "                         'std_train_score',\n",
        "                         'mean_fit_time', \n",
        "                         'std_fit_time',                        \n",
        "                         'mean_score_time', \n",
        "                         'std_score_time']\n",
        "    \n",
        "    # Move the important columns ahead\n",
        "    cv_results = cv_results[important_columns + sorted(list(set(cv_results.columns) - set(important_columns)))]\n",
        "\n",
        "    # Write cv_results file\n",
        "    cv_results.to_csv(path_or_buf=abspath_curr + '/result/titanic/cv_results/GridSearchCV/' + acronym + '.csv', index=False)\n",
        "\n",
        "# Sort best_score_params_estimator_gs in descending order of the best_score_\n",
        "best_score_params_estimator_gs = sorted(best_score_params_estimator_gs, key=lambda x : x[0], reverse=True)\n",
        "\n",
        "# Print best_score_params_estimator_gs\n",
        "pd.DataFrame(best_score_params_estimator_gs, columns=['best_score', 'best_param', 'best_estimator'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "\n",
        "Here we will select best_estimator_gs as the best model. Later we will use this best model to generate the submission file for this kaggle competition."
      ],
      "metadata": {
        "id": "jonCCJgpW1F7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjbLGmXPe32J"
      },
      "outputs": [],
      "source": [
        "# Get the best_score, best_params and best_estimator obtained by GridSearchCV\n",
        "best_score_gs, best_params_gs, best_estimator_gs = best_score_params_estimator_gs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "jTu3oSwQW2oU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "0RPVlucLaz8k"
      }
    }
  ]
}