{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Report.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOLlbkzuYPe+1OjM6IXo6ir",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamkritz/nhlgames/blob/adam_branch/Final%20Report%20(.ipynb)/Final_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "yoooo did you know you can save directly from colab to github? kinda sick"
      ],
      "metadata": {
        "id": "BYj_5kLveUvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "yHlDlg9tWeXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Motivation"
      ],
      "metadata": {
        "id": "Yt7V84DEaHHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NHL and Hockey Terms"
      ],
      "metadata": {
        "id": "r7oMg0ZKZzrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Source"
      ],
      "metadata": {
        "id": "wLVN9jN0Z3yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Goals (Thesis)"
      ],
      "metadata": {
        "id": "A1pK3tboXJ3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Configuration"
      ],
      "metadata": {
        "id": "tX1i8YVHWimM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copied over the usual setup, though we may want to change some later (like the matplotlib stuff)"
      ],
      "metadata": {
        "id": "ygMoK6kVZn_k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3yB94KtgMHu"
      },
      "source": [
        "## Google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWmYBTOwgNs-",
        "outputId": "908d7ea3-ed2c-4dac-e8c4-01b0b6963287",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Get the absolute path of the current folder\n",
        "abspath_curr = '/content/drive/My Drive/Colab Notebooks/teaching/gwu/machine_learning_I/homework/homework_5/'\n",
        "\n",
        "# Get the absolute path of the deep utilities folder\n",
        "abspath_util_deep = '/content/drive/My Drive/Colab Notebooks/teaching/gwu/machine_learning_I/code/utilities/p3_deep_learning/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYZhU1Wqgmqx"
      },
      "source": [
        "## Warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUl4k83e4ANR"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WMODpPfgn2U"
      },
      "source": [
        "## Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBRVH9SB4ANb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "# Set matplotlib sizes\n",
        "plt.rc('font', size=20)\n",
        "plt.rc('axes', titlesize=20)\n",
        "plt.rc('axes', labelsize=20)\n",
        "plt.rc('xtick', labelsize=20)\n",
        "plt.rc('ytick', labelsize=20)\n",
        "plt.rc('legend', fontsize=20)\n",
        "plt.rc('figure', titlesize=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-wNDk5nZhhO"
      },
      "source": [
        "## TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjG43tEnZkfE"
      },
      "outputs": [],
      "source": [
        "# The magic below allows us to use tensorflow version 2.x\n",
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40FN3UNfO2Z7"
      },
      "source": [
        "## Random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSADk0hJP71d"
      },
      "outputs": [],
      "source": [
        "# The random seed\n",
        "random_seed = 42\n",
        "\n",
        "# Set random seed in tensorflow\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "# Set random seed in numpy\n",
        "import numpy as np\n",
        "np.random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Creation (Importing)"
      ],
      "metadata": {
        "id": "1uMEU6vHWoNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will have to decide if we wanna host the data on github/google drive or just download it directly from kaggle. Probably easiest to do through drive like he does, but would require more setup for other people. We could also just host on github if its small enough"
      ],
      "metadata": {
        "id": "TANgdsE8YfUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "FdLHdRNRWveb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "1RYCaKJSWxGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "jonCCJgpW1F7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "jTu3oSwQW2oU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "0RPVlucLaz8k"
      }
    }
  ]
}