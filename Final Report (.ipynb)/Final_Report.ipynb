{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Report.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMMVBtM4TezZ3HvCFz93f4N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamkritz/nhlgames/blob/adam_branch/Final%20Report%20(.ipynb)/Final_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "yoooo did you know you can save directly from colab to github? kinda sick. the path is: Final Report (.ipynb)/Final_Report.ipynb"
      ],
      "metadata": {
        "id": "BYj_5kLveUvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "yHlDlg9tWeXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Motivation"
      ],
      "metadata": {
        "id": "Yt7V84DEaHHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lWsKOdigjylF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NHL and Hockey Terms"
      ],
      "metadata": {
        "id": "r7oMg0ZKZzrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fRuow2MgjzMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Source"
      ],
      "metadata": {
        "id": "wLVN9jN0Z3yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9GSXurLZjzsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Goals (Thesis)"
      ],
      "metadata": {
        "id": "A1pK3tboXJ3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qQtN9phoj0MS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Configuration"
      ],
      "metadata": {
        "id": "tX1i8YVHWimM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copied over the usual setup, though we may want to change some later (like the matplotlib stuff)"
      ],
      "metadata": {
        "id": "ygMoK6kVZn_k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3yB94KtgMHu"
      },
      "source": [
        "## Google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWmYBTOwgNs-",
        "outputId": "908d7ea3-ed2c-4dac-e8c4-01b0b6963287",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Get the absolute path of the current folder\n",
        "abspath_curr = '/content/drive/My Drive/Colab Notebooks/teaching/gwu/machine_learning_I/homework/homework_5/'\n",
        "\n",
        "# Get the absolute path of the deep utilities folder\n",
        "abspath_util_deep = '/content/drive/My Drive/Colab Notebooks/teaching/gwu/machine_learning_I/code/utilities/p3_deep_learning/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYZhU1Wqgmqx"
      },
      "source": [
        "## Warning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUl4k83e4ANR"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WMODpPfgn2U"
      },
      "source": [
        "## Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBRVH9SB4ANb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "# Set matplotlib sizes\n",
        "plt.rc('font', size=20)\n",
        "plt.rc('axes', titlesize=20)\n",
        "plt.rc('axes', labelsize=20)\n",
        "plt.rc('xtick', labelsize=20)\n",
        "plt.rc('ytick', labelsize=20)\n",
        "plt.rc('legend', fontsize=20)\n",
        "plt.rc('figure', titlesize=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-wNDk5nZhhO"
      },
      "source": [
        "## TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjG43tEnZkfE"
      },
      "outputs": [],
      "source": [
        "# The magic below allows us to use tensorflow version 2.x\n",
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40FN3UNfO2Z7"
      },
      "source": [
        "## Random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSADk0hJP71d"
      },
      "outputs": [],
      "source": [
        "# The random seed\n",
        "random_seed = 42\n",
        "\n",
        "# Set random seed in tensorflow\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "# Set random seed in numpy\n",
        "import numpy as np\n",
        "np.random.seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Creation (Importing)"
      ],
      "metadata": {
        "id": "1uMEU6vHWoNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will have to decide if we wanna host the data on github/google drive or just download it directly from kaggle. Probably easiest to do through drive like he does, but would require more setup for other people. We could also just host on github if its small enough"
      ],
      "metadata": {
        "id": "TANgdsE8YfUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "game = pd.read_csv('https://raw.githubusercontent.com/adamkritz/nhlgames/main/Data/game.csv')\n",
        "team_stats = pd.read_csv('https://raw.githubusercontent.com/adamkritz/nhlgames/main/Data/game_teams_stats.csv')\n",
        "team_info = pd.read_csv('https://raw.githubusercontent.com/adamkritz/nhlgames/main/Data/team_info.csv')"
      ],
      "metadata": {
        "id": "VZlqqcD9e2YV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "FdLHdRNRWveb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "This code was taken from: https://github.com/yuxiaohuang/teaching/blob/master/gwu/machine_learning_I/spring_2022/code/p2_shallow_learning/p2_c2_supervised_learning/p2_c2_s5_tree_based_models/case_study/case_study.ipynb \n",
        "\n",
        "These three models are a culmination of all the models we learned for classification. It has logistic regression, shallow neural networks, and random forest classifier (and als the histgradientboosting one). This was used to classify titanic survival as Yes or No, so it will probably be good for us."
      ],
      "metadata": {
        "id": "1RYCaKJSWxGj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYCH8GB-e31z"
      },
      "source": [
        "## Creating the dictionary of the models\n",
        "- In the dictionary:\n",
        "    - the key is the acronym of the model\n",
        "    - the value is the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5h3IQo9e31z"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "models = {'lr': LogisticRegression(class_weight='balanced', random_state=random_seed),\n",
        "          'mlpc': MLPClassifier(early_stopping=True, random_state=random_seed),\n",
        "          'rfc': RandomForestClassifier(class_weight='balanced', random_state=random_seed),\n",
        "          'hgbc': HistGradientBoostingClassifier(random_state=random_seed)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju9FdEVce310"
      },
      "source": [
        "## Creating the dictionary of the pipelines\n",
        "In the dictionary:\n",
        "- the key is the acronym of the model\n",
        "- the value is the pipeline, which, for now, only includes the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc-L-914e310"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipes = {}\n",
        "\n",
        "for acronym, model in models.items():\n",
        "    pipes[acronym] = Pipeline([('model', model)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgkFbGGKe311"
      },
      "source": [
        "## Getting the predefined split cross-validator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FAACb8ke311",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get the:\n",
        "# feature matrix and target velctor in the combined training and validation data\n",
        "# target vector in the combined training and validation data\n",
        "# PredefinedSplit\n",
        "# See the implementation in pmlm_utilities.ipynb\n",
        "X_train_val, y_train_val, ps = get_train_val_ps(X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3rZoMqZe312"
      },
      "source": [
        "## GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E08xqUQve313"
      },
      "source": [
        "### Creating the dictionary of the parameter grids\n",
        "- In the dictionary:\n",
        "    - the key is the acronym of the model\n",
        "    - the value is the parameter grid of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3OWujL3e313"
      },
      "outputs": [],
      "source": [
        "param_grids = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EyKhepjmV6P"
      },
      "source": [
        "#### The parameter grid for LogisticRegression\n",
        "- The hyperparameters we want to fine-tune are:\n",
        "    - tol\n",
        "    - C\n",
        "- See details of the meaning of the hyperparametes in [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2Mv1rffnJpN"
      },
      "outputs": [],
      "source": [
        "# The parameter grid of tol\n",
        "tol_grid = [10 ** -5, 10 ** -4, 10 ** -3]\n",
        "\n",
        "# The parameter grid of C\n",
        "C_grid = [0.1, 1, 10]\n",
        "\n",
        "# Update param_grids\n",
        "param_grids['lr'] = [{'model__tol': tol_grid,\n",
        "                      'model__C': C_grid}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bco06XPK4APO"
      },
      "source": [
        "#### The parameter grid for MLPClassifier\n",
        "- The hyperparameters we want to fine-tune are:\n",
        "    - alpha\n",
        "    - learning_rate_init\n",
        "\n",
        "- See details of the meaning of the hyperparametes in [sklearn.neural_network.MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEuags7e4APO"
      },
      "outputs": [],
      "source": [
        "# The grids for alpha\n",
        "alpha_grids = [10 ** i for i in range(-5, -2)]\n",
        "\n",
        "# The grids for learning_rate_init\n",
        "learning_rate_init_grids = [10 ** i for i in range(-4, -1)]\n",
        "\n",
        "# Update param_grids\n",
        "param_grids['mlpc'] = [{'model__alpha': alpha_grids,\n",
        "                        'model__learning_rate_init': learning_rate_init_grids}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Synl8u9cC8"
      },
      "source": [
        "#### The parameter grid for random forest\n",
        "- The hyperparameters we want to fine-tune are:\n",
        "    - min_samples_split\n",
        "    - min_samples_leaf\n",
        "\n",
        "- See details of the meaning of the hyperparametes in [sklearn.ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pIhWeST9cC8"
      },
      "outputs": [],
      "source": [
        "# The grids for min_samples_split\n",
        "min_samples_split_grids = [2, 20, 100]\n",
        "\n",
        "# The grids for min_samples_leaf\n",
        "min_samples_leaf_grids = [1, 20, 100]\n",
        "\n",
        "# Update param_grids\n",
        "param_grids['rfc'] = [{'model__min_samples_split': min_samples_split_grids,\n",
        "                       'model__min_samples_leaf': min_samples_leaf_grids}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmuPjEKN9cC-"
      },
      "source": [
        "#### The parameter grid for histogram-based gradient boosting\n",
        "- The hyperparameters we want to fine-tune are:\n",
        "- learning_rate\n",
        "- min_samples_leaf\n",
        "\n",
        "- See details of the meaning of the hyperparametes in [sklearn.ensemble.HistGradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAj6ezza9cC-"
      },
      "outputs": [],
      "source": [
        "# The grids for learning_rate\n",
        "learning_rate_grids = [10 ** i for i in range(-3, 2)]\n",
        "\n",
        "# The grids for min_samples_leaf\n",
        "min_samples_leaf_grids = [1, 20, 100]\n",
        "\n",
        "# Update param_grids\n",
        "param_grids['hgbc'] = [{'model__learning_rate': learning_rate_grids,\n",
        "                        'model__min_samples_leaf': min_samples_leaf_grids}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRabeGs4WaHX"
      },
      "source": [
        "### Creating the directory for the cv results produced by GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO7Yd15JWaHY"
      },
      "outputs": [],
      "source": [
        "# Make directory\n",
        "directory = os.path.dirname(abspath_curr + '/result/titanic/cv_results/GridSearchCV/')\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVIuo08Ze31-"
      },
      "source": [
        "### Tuning the hyperparameters\n",
        "The code below shows how to fine-tune the hyperparameters of SGDRegressor and LinearRegression_MBGD using sklearn GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "DwA4WZlFe31-",
        "outputId": "e8a5f8fc-0f40-499d-85f3-be192bb5534d",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>best_score</th>\n",
              "      <th>best_param</th>\n",
              "      <th>best_estimator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.827220</td>\n",
              "      <td>{'model__learning_rate': 0.1, 'model__min_samp...</td>\n",
              "      <td>(HistGradientBoostingClassifier(l2_regularizat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.802505</td>\n",
              "      <td>{'model__min_samples_leaf': 1, 'model__min_sam...</td>\n",
              "      <td>((DecisionTreeClassifier(ccp_alpha=0.0, class_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.773968</td>\n",
              "      <td>{'model__alpha': 1e-05, 'model__learning_rate_...</td>\n",
              "      <td>(MLPClassifier(activation='relu', alpha=1e-05,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.765205</td>\n",
              "      <td>{'model__C': 1, 'model__tol': 1e-05}</td>\n",
              "      <td>(LogisticRegression(C=1, class_weight='balance...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   best_score  ...                                     best_estimator\n",
              "0    0.827220  ...  (HistGradientBoostingClassifier(l2_regularizat...\n",
              "1    0.802505  ...  ((DecisionTreeClassifier(ccp_alpha=0.0, class_...\n",
              "2    0.773968  ...  (MLPClassifier(activation='relu', alpha=1e-05,...\n",
              "3    0.765205  ...  (LogisticRegression(C=1, class_weight='balance...\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "execution_count": 62,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# The list of [best_score_, best_params_, best_estimator_] obtained by GridSearchCV\n",
        "best_score_params_estimator_gs = []\n",
        "\n",
        "# For each model\n",
        "for acronym in pipes.keys():\n",
        "    # GridSearchCV\n",
        "    gs = GridSearchCV(estimator=pipes[acronym],\n",
        "                      param_grid=param_grids[acronym],\n",
        "                      scoring='f1_macro',\n",
        "                      n_jobs=2,\n",
        "                      cv=ps,\n",
        "                      return_train_score=True)\n",
        "        \n",
        "    # Fit the pipeline\n",
        "    gs = gs.fit(X_train_val, y_train_val)\n",
        "    \n",
        "    # Update best_score_params_estimator_gs\n",
        "    best_score_params_estimator_gs.append([gs.best_score_, gs.best_params_, gs.best_estimator_])\n",
        "    \n",
        "    # Sort cv_results in ascending order of 'rank_test_score' and 'std_test_score'\n",
        "    cv_results = pd.DataFrame.from_dict(gs.cv_results_).sort_values(by=['rank_test_score', 'std_test_score'])\n",
        "    \n",
        "    # Get the important columns in cv_results\n",
        "    important_columns = ['rank_test_score',\n",
        "                         'mean_test_score', \n",
        "                         'std_test_score', \n",
        "                         'mean_train_score', \n",
        "                         'std_train_score',\n",
        "                         'mean_fit_time', \n",
        "                         'std_fit_time',                        \n",
        "                         'mean_score_time', \n",
        "                         'std_score_time']\n",
        "    \n",
        "    # Move the important columns ahead\n",
        "    cv_results = cv_results[important_columns + sorted(list(set(cv_results.columns) - set(important_columns)))]\n",
        "\n",
        "    # Write cv_results file\n",
        "    cv_results.to_csv(path_or_buf=abspath_curr + '/result/titanic/cv_results/GridSearchCV/' + acronym + '.csv', index=False)\n",
        "\n",
        "# Sort best_score_params_estimator_gs in descending order of the best_score_\n",
        "best_score_params_estimator_gs = sorted(best_score_params_estimator_gs, key=lambda x : x[0], reverse=True)\n",
        "\n",
        "# Print best_score_params_estimator_gs\n",
        "pd.DataFrame(best_score_params_estimator_gs, columns=['best_score', 'best_param', 'best_estimator'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "\n",
        "Here we will select best_estimator_gs as the best model. Later we will use this best model to generate the submission file for this kaggle competition."
      ],
      "metadata": {
        "id": "jonCCJgpW1F7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjbLGmXPe32J"
      },
      "outputs": [],
      "source": [
        "# Get the best_score, best_params and best_estimator obtained by GridSearchCV\n",
        "best_score_gs, best_params_gs, best_estimator_gs = best_score_params_estimator_gs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "jTu3oSwQW2oU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "0RPVlucLaz8k"
      }
    }
  ]
}